{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam # not important as there's no training here.\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115b6c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[2].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(5000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# x_train = mnist.train.images.reshape(-1, img_rows, img_cols, 1)\n",
    "# x_valid = mnist.validation.images.reshape(-1, img_rows, img_cols, 1)\n",
    "# x_test = mnist.test.images.reshape(-1, img_rows, img_cols, 1)\n",
    "\n",
    "x_train = mnist.train.images\n",
    "x_valid = mnist.validation.images\n",
    "x_test = mnist.test.images\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_valid))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "(5000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = mnist.train.labels\n",
    "y_valid = mnist.validation.labels\n",
    "y_test = mnist.test.labels\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_valid))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))\n",
    "layer_1 = Dense(784)(input_layer)\n",
    "output_layer = Dense(num_classes, activation='softmax')(layer_1)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(Adam(), 'mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer= Adam(), loss='mse')\n",
    "\n",
    "\n",
    "\n",
    "# input_layer = Input(shape=(5,1))\n",
    "# layer = Dense(8)(input_layer)\n",
    "# output_layer = Dense(3)(layer)\n",
    "# model = Model(input_layer, output_layer)\n",
    "# model.compile(Adam(), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvolutionStrategy(object):\n",
    "\n",
    "    def __init__(self, weights, get_reward_func, population_size=50, sigma=0.1, learning_rate=0.001):\n",
    "        np.random.seed(0)\n",
    "        self.weights = weights\n",
    "        self.get_reward = get_reward_func\n",
    "        self.POPULATION_SIZE = population_size\n",
    "        self.SIGMA = sigma\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "\n",
    "\n",
    "    def _get_weights_try(self, w, p):\n",
    "        weights_try = []\n",
    "        for index, i in enumerate(p):\n",
    "            jittered = self.SIGMA*i\n",
    "            weights_try.append(w[index] + jittered)\n",
    "        return weights_try\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "    def run(self, iterations, print_step=10):\n",
    "        for iteration in range(iterations):\n",
    "\n",
    "            if iteration % print_step == 0:\n",
    "                print('iter %d. reward: %f' % (iteration, self.get_reward(self.weights)))\n",
    "\n",
    "            population = []\n",
    "            rewards = np.zeros(self.POPULATION_SIZE)\n",
    "            for i in range(self.POPULATION_SIZE):\n",
    "                x = []\n",
    "                for w in self.weights:                 \n",
    "                    x.append(np.random.randn(*w.shape))\n",
    "                population.append(x)\n",
    "            \n",
    "            for i in range(self.POPULATION_SIZE):\n",
    "                weights_try = self._get_weights_try(self.weights, population[i])\n",
    "                rewards[i]  = self.get_reward(weights_try)\n",
    "            \n",
    "            rewards = (rewards - np.mean(rewards)) / np.std(rewards)\n",
    "\n",
    "            for index, w in enumerate(self.weights):\n",
    "                A = np.array([p[index] for p in population])\n",
    "                self.weights[index] = w + self.LEARNING_RATE/(self.POPULATION_SIZE*self.SIGMA) * np.dot(A.T, rewards).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(weights):\n",
    "    start_index = np.random.choice(y_train.shape[0]-batch_size-1,1)[0]\n",
    "    solution = y_train[start_index:start_index+batch_size]\n",
    "    inp = x_train[start_index:start_index+batch_size]\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    prediction = model.predict(inp)\n",
    "    #print(prediction)\n",
    "\n",
    "    #accuracy = (np.mean(np.equal(np.argmax(prediction), np.argmax(solution))))\n",
    "    #print('accuracy:', accuracy)\n",
    "\n",
    "    reward = -np.sum(np.square(solution - prediction))\n",
    "    #reward = np.mean(np.equal(np.argmax(prediction), np.argmax(solution)))\n",
    "    return reward\n",
    "\n",
    "# def get_reward(weights):\n",
    "#     solution = np.array([0.5, 0.1, -0.3])\n",
    "#     inp = np.asarray([[1,2,3,4,5]])\n",
    "#     inp = np.expand_dims(inp, -1)\n",
    "    \n",
    "#     model.set_weights(weights)\n",
    "#     prediction = model.predict(inp)[0]\n",
    "#     # here our best reward is zero\n",
    "#     reward = -np.mean(np.square(solution - prediction))\n",
    "#     return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 784)\n",
      "(784,)\n",
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for i in model.get_weights():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. reward: -117.537794\n",
      "iter 10. reward: -115.959539\n",
      "iter 20. reward: -114.769395\n",
      "iter 30. reward: -115.323557\n",
      "iter 40. reward: -115.024518\n",
      "iter 50. reward: -112.120282\n",
      "iter 60. reward: -111.588756\n",
      "iter 70. reward: -108.683120\n",
      "iter 80. reward: -108.715734\n",
      "iter 90. reward: -106.373435\n",
      "iter 100. reward: -105.847861\n",
      "iter 110. reward: -103.307791\n",
      "iter 120. reward: -98.713469\n",
      "iter 130. reward: -104.438891\n",
      "iter 140. reward: -99.905645\n",
      "iter 150. reward: -97.672412\n",
      "iter 160. reward: -105.081657\n",
      "iter 170. reward: -99.912359\n",
      "iter 180. reward: -101.594007\n",
      "iter 190. reward: -93.135164\n",
      "iter 200. reward: -101.110040\n",
      "iter 210. reward: -97.058952\n",
      "iter 220. reward: -95.576623\n",
      "iter 230. reward: -86.673647\n",
      "iter 240. reward: -87.290171\n",
      "iter 250. reward: -82.205154\n",
      "iter 260. reward: -84.573878\n",
      "iter 270. reward: -78.463883\n",
      "iter 280. reward: -80.094559\n",
      "iter 290. reward: -78.969926\n",
      "iter 300. reward: -87.946822\n",
      "iter 310. reward: -83.135224\n",
      "iter 320. reward: -87.582897\n",
      "iter 330. reward: -81.248430\n",
      "iter 340. reward: -88.923753\n",
      "iter 350. reward: -90.109399\n",
      "iter 360. reward: -71.231614\n",
      "iter 370. reward: -67.388524\n",
      "iter 380. reward: -81.358236\n",
      "iter 390. reward: -77.139197\n",
      "iter 400. reward: -66.175742\n",
      "iter 410. reward: -80.059510\n",
      "iter 420. reward: -69.889351\n",
      "iter 430. reward: -76.772195\n",
      "iter 440. reward: -77.221794\n",
      "iter 450. reward: -66.522627\n",
      "iter 460. reward: -62.100046\n",
      "iter 470. reward: -55.450774\n",
      "iter 480. reward: -80.756631\n",
      "iter 490. reward: -77.420148\n",
      "iter 500. reward: -77.025830\n",
      "iter 510. reward: -70.640157\n",
      "iter 520. reward: -74.691646\n",
      "iter 530. reward: -56.808631\n",
      "iter 540. reward: -68.132114\n",
      "iter 550. reward: -75.145477\n",
      "iter 560. reward: -71.798067\n",
      "iter 570. reward: -61.111757\n",
      "iter 580. reward: -67.297900\n",
      "iter 590. reward: -63.220695\n",
      "iter 600. reward: -65.940992\n",
      "iter 610. reward: -86.103339\n",
      "iter 620. reward: -61.782214\n",
      "iter 630. reward: -59.462222\n",
      "iter 640. reward: -56.726893\n",
      "iter 650. reward: -68.322815\n",
      "iter 660. reward: -67.614993\n",
      "iter 670. reward: -77.087901\n",
      "iter 680. reward: -66.927407\n",
      "iter 690. reward: -65.721663\n",
      "iter 700. reward: -59.291400\n",
      "iter 710. reward: -64.922900\n",
      "iter 720. reward: -55.372060\n",
      "iter 730. reward: -64.985275\n",
      "iter 740. reward: -75.323347\n",
      "iter 750. reward: -52.588733\n",
      "iter 760. reward: -52.591093\n",
      "iter 770. reward: -52.962627\n",
      "iter 780. reward: -63.665128\n",
      "iter 790. reward: -59.180411\n",
      "iter 800. reward: -62.529627\n",
      "iter 810. reward: -57.097334\n",
      "iter 820. reward: -43.777106\n",
      "iter 830. reward: -49.760059\n",
      "iter 840. reward: -57.870267\n",
      "iter 850. reward: -51.616756\n",
      "iter 860. reward: -68.100960\n",
      "iter 870. reward: -60.294446\n",
      "iter 880. reward: -58.202937\n",
      "iter 890. reward: -43.519129\n",
      "iter 900. reward: -50.239248\n",
      "iter 910. reward: -53.728910\n",
      "iter 920. reward: -39.009266\n",
      "iter 930. reward: -50.483725\n",
      "iter 940. reward: -39.079806\n",
      "iter 950. reward: -51.458895\n",
      "iter 960. reward: -39.317648\n",
      "iter 970. reward: -36.735373\n",
      "iter 980. reward: -49.512430\n",
      "iter 990. reward: -62.243283\n"
     ]
    }
   ],
   "source": [
    "es = EvolutionStrategy(model.get_weights(), get_reward, population_size=50, sigma=0.1, learning_rate=0.001)\n",
    "es.run(1000, print_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38900000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set prediction\n",
    "pediction = model.predict(x_valid)\n",
    "solution = y_valid\n",
    "np.mean(np.equal(np.argmax(pediction,1), np.argmax(solution,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42241"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = np.random.choice(y_train.shape[0]-batch_size,1)[0]\n",
    "start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42240"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[54871:54871+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54871"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]-batch_size-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
