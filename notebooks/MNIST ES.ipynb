{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam # not important as there's no training here.\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c15588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[2].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(5000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# x_train = mnist.train.images.reshape(-1, img_rows, img_cols, 1)\n",
    "# x_valid = mnist.validation.images.reshape(-1, img_rows, img_cols, 1)\n",
    "# x_test = mnist.test.images.reshape(-1, img_rows, img_cols, 1)\n",
    "\n",
    "x_train = mnist.train.images\n",
    "x_valid = mnist.validation.images\n",
    "x_test = mnist.test.images\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_valid))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "(5000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = mnist.train.labels\n",
    "y_valid = mnist.validation.labels\n",
    "y_test = mnist.test.labels\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_valid))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(784,))\n",
    "layer_1 = Dense(784)(input_layer)\n",
    "output_layer = Dense(num_classes, activation='softmax')(layer_1)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(Adam(), 'mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer= Adam(), loss='mse')\n",
    "\n",
    "\n",
    "\n",
    "# input_layer = Input(shape=(5,1))\n",
    "# layer = Dense(8)(input_layer)\n",
    "# output_layer = Dense(3)(layer)\n",
    "# model = Model(input_layer, output_layer)\n",
    "# model.compile(Adam(), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_20/Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvolutionStrategy(object):\n",
    "\n",
    "    def __init__(self, weights, get_reward_func, population_size=50, sigma=0.1, learning_rate=0.001):\n",
    "        np.random.seed(0)\n",
    "        self.weights = weights\n",
    "        self.get_reward = get_reward_func\n",
    "        self.POPULATION_SIZE = population_size\n",
    "        self.SIGMA = sigma\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "\n",
    "\n",
    "    def _get_weights_try(self, w, p):\n",
    "        weights_try = []\n",
    "        for index, i in enumerate(p):\n",
    "            jittered = self.SIGMA*i\n",
    "            weights_try.append(w[index] + jittered)\n",
    "        return weights_try\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "\n",
    "\n",
    "    def run(self, iterations, print_step=10):\n",
    "        for iteration in range(iterations):\n",
    "\n",
    "            if iteration % print_step == 0:\n",
    "                print('iter %d. reward: %f' % (iteration, self.get_reward(self.weights)))\n",
    "\n",
    "            population = []\n",
    "            rewards = np.zeros(self.POPULATION_SIZE)\n",
    "            for i in range(self.POPULATION_SIZE):\n",
    "                x = []\n",
    "                for w in self.weights:                 \n",
    "                    x.append(np.random.randn(*w.shape))\n",
    "                population.append(x)\n",
    "\n",
    "            for i in range(self.POPULATION_SIZE):\n",
    "                weights_try = self._get_weights_try(self.weights, population[i])\n",
    "                rewards[i]  = self.get_reward(weights_try)\n",
    "            \n",
    "            rewards = (rewards - np.mean(rewards)) / np.std(rewards)\n",
    "\n",
    "            for index, w in enumerate(self.weights):\n",
    "                A = np.array([p[index] for p in population])\n",
    "                self.weights[index] = w + self.LEARNING_RATE/(self.POPULATION_SIZE*self.SIGMA) * np.dot(A.T, rewards).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(weights):\n",
    "    start_index = np.random.choice(y_train.shape[0]-batch_size,1)[0]-1\n",
    "    solution = y_train[start_index:start_index+batch_size]\n",
    "    inp = x_train[start_index:start_index+batch_size]\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    prediction = model.predict(inp)[0]\n",
    "    print(prediction.shape, solution.shape)\n",
    "    print(prediction)\n",
    "\n",
    "    accuracy = (np.mean(np.equal(np.argmax(prediction), np.argmax(solution,1))))\n",
    "\n",
    "    reward = -np.sum(np.square(solution - prediction))\n",
    "    #reward = np.mean(np.equal(np.argmax(prediction), np.argmax(solution)))\n",
    "    return reward\n",
    "\n",
    "# def get_reward(weights):\n",
    "#     solution = np.array([0.5, 0.1, -0.3])\n",
    "#     inp = np.asarray([[1,2,3,4,5]])\n",
    "#     inp = np.expand_dims(inp, -1)\n",
    "    \n",
    "#     model.set_weights(weights)\n",
    "#     prediction = model.predict(inp)[0]\n",
    "#     # here our best reward is zero\n",
    "#     reward = -np.mean(np.square(solution - prediction))\n",
    "#     return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (128, 10)\n",
      "[ 0.0659879   0.14966287  0.10078061  0.06346384  0.07194627  0.17012163\n",
      "  0.13442235  0.06233007  0.09860066  0.08268385]\n",
      "iter 0. reward: -116.665075\n",
      "(10,) (128, 10)\n",
      "[  3.34300508e-04   8.44028487e-04   4.18112986e-03   1.45802438e-01\n",
      "   1.63962692e-02   5.83071589e-01   8.27028975e-02   2.27109231e-05\n",
      "   1.64287791e-01   2.35680398e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.55437796e-04   6.53196722e-02   1.91685413e-05   1.20812252e-01\n",
      "   3.94856125e-01   1.19745769e-02   1.33684254e-03   1.47679617e-04\n",
      "   1.55161440e-01   2.50216752e-01]\n",
      "(10,) (128, 10)\n",
      "[  3.96028161e-04   9.49970970e-04   7.13945992e-05   5.94174862e-03\n",
      "   1.55331014e-04   1.47255985e-08   4.65908609e-02   4.34793378e-07\n",
      "   9.45603967e-01   2.90317228e-04]\n",
      "(10,) (128, 10)\n",
      "[ 0.00382885  0.00857371  0.00351855  0.3316164   0.01681288  0.57253563\n",
      "  0.00228409  0.04021961  0.0033537   0.01725659]\n",
      "(10,) (128, 10)\n",
      "[  6.19637743e-02   1.69685925e-03   1.34869455e-03   4.44507413e-03\n",
      "   4.78325383e-05   1.80606004e-02   5.68309486e-01   3.78884375e-02\n",
      "   3.04927707e-01   1.31153071e-03]\n",
      "(10,) (128, 10)\n",
      "[  3.09531353e-02   9.93625075e-03   1.07910791e-02   1.16904201e-02\n",
      "   1.56622574e-01   7.71758795e-01   5.45789581e-03   1.35390786e-04\n",
      "   2.50891736e-03   1.45609971e-04]\n",
      "(10,) (128, 10)\n",
      "[  2.45383140e-02   1.19423705e-04   3.15467769e-05   9.78883877e-02\n",
      "   7.07635805e-02   7.60039985e-01   1.05961822e-02   1.46776743e-04\n",
      "   8.55394080e-03   2.73217857e-02]\n",
      "(10,) (128, 10)\n",
      "[  2.16879183e-04   3.17681115e-03   9.19724047e-01   1.92422212e-05\n",
      "   8.44344777e-06   7.51206130e-02   4.07323605e-05   2.90683703e-04\n",
      "   9.25498898e-06   1.39325939e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.95203873e-04   1.02777150e-03   5.59703112e-01   1.63119838e-01\n",
      "   2.60450621e-03   9.14277434e-02   1.68649698e-04   8.82337044e-05\n",
      "   1.81602806e-01   6.20873907e-05]\n",
      "(10,) (128, 10)\n",
      "[  1.90540124e-02   6.47453417e-04   1.72222570e-01   5.89731261e-02\n",
      "   1.04313893e-02   2.73905154e-02   4.10473049e-01   2.39871323e-01\n",
      "   6.05471879e-02   3.89327673e-04]\n",
      "(10,) (128, 10)\n",
      "[ 0.0332997   0.01659421  0.02000644  0.8037957   0.00440164  0.0287369\n",
      "  0.05027695  0.00471892  0.03510793  0.0030615 ]\n",
      "(10,) (128, 10)\n",
      "[ 0.34853297  0.00048025  0.12030394  0.1276456   0.01802661  0.02654945\n",
      "  0.17271252  0.16218513  0.00267073  0.02089274]\n",
      "(10,) (128, 10)\n",
      "[  1.62137579e-03   3.70298564e-01   2.29589939e-02   1.97818130e-02\n",
      "   1.11860260e-02   1.61291827e-02   4.02697511e-02   3.70752951e-03\n",
      "   5.13965011e-01   8.17034088e-05]\n",
      "(10,) (128, 10)\n",
      "[  2.20751826e-04   9.10429866e-04   7.21227610e-04   4.74028215e-02\n",
      "   4.86325589e-05   8.90182629e-02   5.26340127e-01   6.34447299e-03\n",
      "   7.44642466e-06   3.28985780e-01]\n",
      "(10,) (128, 10)\n",
      "[  1.12315129e-05   3.21610918e-04   3.26843839e-03   9.90207851e-01\n",
      "   3.94416820e-05   7.49659594e-05   5.25400601e-03   7.51773012e-04\n",
      "   1.43592015e-05   5.61741726e-05]\n",
      "(10,) (128, 10)\n",
      "[ 0.03484729  0.01797547  0.03407497  0.73201418  0.04281063  0.00524923\n",
      "  0.06126911  0.01079988  0.0026679   0.05829136]\n",
      "(10,) (128, 10)\n",
      "[  1.92381427e-01   1.80917293e-01   4.56507078e-05   1.23599827e-01\n",
      "   1.05297022e-01   9.77422949e-03   1.96354842e-04   3.02125841e-01\n",
      "   1.61713101e-02   6.94909915e-02]\n",
      "(10,) (128, 10)\n",
      "[  2.92694068e-07   5.07990597e-03   9.96295596e-04   7.06721970e-04\n",
      "   7.41885975e-03   7.67376856e-04   1.20730503e-04   9.84229863e-01\n",
      "   6.75582793e-04   4.51564529e-06]\n",
      "(10,) (128, 10)\n",
      "[  2.25560769e-04   4.49846033e-03   1.42760783e-01   9.47604552e-02\n",
      "   2.30185222e-03   5.00735700e-01   5.32376282e-02   5.60519472e-02\n",
      "   2.71906378e-03   1.42708570e-01]\n",
      "(10,) (128, 10)\n",
      "[  5.19442314e-04   9.49232572e-07   1.40099183e-01   1.14595832e-03\n",
      "   1.66957721e-01   4.41701559e-04   6.88145985e-04   1.11482767e-02\n",
      "   4.08274710e-01   2.70723969e-01]\n",
      "(10,) (128, 10)\n",
      "[  2.03078315e-02   3.78720986e-04   2.05334798e-01   1.06868455e-02\n",
      "   6.69184234e-03   4.05287296e-02   5.67870557e-01   1.47821203e-01\n",
      "   3.58817750e-04   2.07569174e-05]\n",
      "(10,) (128, 10)\n",
      "[  1.63538891e-04   5.92354801e-04   9.42330480e-01   6.90021599e-03\n",
      "   1.75818969e-02   6.10092538e-04   5.04020718e-04   3.20681943e-06\n",
      "   3.13040018e-02   1.01431860e-05]\n",
      "(10,) (128, 10)\n",
      "[  2.99520314e-01   2.00503482e-03   3.69650461e-02   2.60620005e-03\n",
      "   6.26750663e-02   1.20380307e-02   2.53559974e-05   1.00029580e-01\n",
      "   4.82163638e-01   1.97167019e-03]\n",
      "(10,) (128, 10)\n",
      "[  9.72213894e-02   1.09871589e-01   7.44199939e-03   2.39294881e-04\n",
      "   6.19112700e-02   1.11849084e-02   1.25175400e-03   7.08481908e-01\n",
      "   1.25160313e-03   1.14425970e-03]\n",
      "(10,) (128, 10)\n",
      "[  7.05960701e-05   6.59167767e-02   6.61174878e-02   1.52406543e-01\n",
      "   3.65890935e-02   1.36629632e-02   1.07515119e-01   5.53450584e-01\n",
      "   3.28017253e-04   3.94293061e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.20886125e-06   1.56171247e-01   1.86430314e-03   8.10366869e-01\n",
      "   1.07813403e-02   1.01259675e-05   6.39536744e-03   2.85010226e-03\n",
      "   8.73592217e-03   2.82355701e-03]\n",
      "(10,) (128, 10)\n",
      "[ 0.0303955   0.01404839  0.04969354  0.02774287  0.32747903  0.03397245\n",
      "  0.08755609  0.00319036  0.40730718  0.01861458]\n",
      "(10,) (128, 10)\n",
      "[  7.85169005e-01   2.20975205e-02   2.66956910e-03   1.25417537e-05\n",
      "   1.62909091e-01   1.31242815e-03   2.47039460e-02   8.58160725e-04\n",
      "   1.91199324e-05   2.48655997e-04]\n",
      "(10,) (128, 10)\n",
      "[  5.30308485e-03   1.09568591e-05   8.83505709e-05   1.72589195e-03\n",
      "   2.84207286e-04   8.72665703e-01   7.09940419e-02   2.22836577e-04\n",
      "   3.74239162e-02   1.12810982e-02]\n",
      "(10,) (128, 10)\n",
      "[  8.23678988e-07   9.66522028e-04   5.63625693e-01   4.18318482e-03\n",
      "   8.66270275e-04   9.90631152e-03   1.72827622e-05   2.02779099e-03\n",
      "   6.77307326e-05   4.18338448e-01]\n",
      "(10,) (128, 10)\n",
      "[  3.16186510e-02   7.25506470e-02   6.08114824e-02   6.49551094e-01\n",
      "   7.38767907e-02   8.80429894e-02   1.07643122e-04   2.51619774e-03\n",
      "   4.51038417e-04   2.04734635e-02]\n",
      "(10,) (128, 10)\n",
      "[  5.71392849e-02   3.38236839e-02   1.16452237e-03   8.18615896e-04\n",
      "   1.90596911e-03   8.39364231e-01   1.68720353e-03   1.76036870e-03\n",
      "   5.71369454e-02   5.19927498e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.95625489e-05   1.58649590e-03   2.41504404e-05   1.13501037e-02\n",
      "   2.39933114e-02   1.90022647e-01   7.71462262e-01   7.10533815e-04\n",
      "   6.27537433e-04   2.03355972e-04]\n",
      "(10,) (128, 10)\n",
      "[  9.15977173e-04   2.06502527e-02   1.56258931e-04   1.30370609e-04\n",
      "   9.69610453e-01   1.76063704e-03   1.31496156e-04   5.97291021e-03\n",
      "   8.71173761e-05   5.84409805e-04]\n",
      "(10,) (128, 10)\n",
      "[  4.16185558e-01   2.99421605e-03   8.36021677e-02   8.28802958e-03\n",
      "   1.29196309e-02   4.71600235e-01   5.62900561e-04   3.63960024e-03\n",
      "   8.66366317e-05   1.21030629e-04]\n",
      "(10,) (128, 10)\n",
      "[  5.51284349e-04   1.99322565e-03   1.97968483e-02   9.51117463e-03\n",
      "   8.49529344e-04   1.34280277e-03   7.30726751e-04   4.00269142e-04\n",
      "   8.92310739e-01   7.25133419e-02]\n",
      "(10,) (128, 10)\n",
      "[  4.51168828e-02   2.46502203e-03   6.39012922e-03   7.85318948e-03\n",
      "   2.99668193e-01   8.11717939e-03   1.73081402e-02   5.32425463e-01\n",
      "   8.06151256e-02   4.06537038e-05]\n",
      "(10,) (128, 10)\n",
      "[  2.99709663e-03   3.13192129e-01   3.59951984e-04   6.25537455e-01\n",
      "   2.06336821e-03   6.94970321e-03   1.02339382e-03   4.34284806e-02\n",
      "   3.73315695e-03   7.15332048e-04]\n",
      "(10,) (128, 10)\n",
      "[  2.00317078e-03   2.22180933e-02   5.14699519e-02   7.23914430e-02\n",
      "   1.17948234e-01   4.53049596e-03   1.93179939e-02   1.68180559e-02\n",
      "   1.44265156e-04   6.93158329e-01]\n",
      "(10,) (128, 10)\n",
      "[  1.05575396e-10   9.99872208e-01   3.19092530e-11   7.76429303e-08\n",
      "   3.67444741e-08   1.23526144e-04   1.16078276e-13   8.78291797e-13\n",
      "   4.22433368e-06   1.35873656e-14]\n",
      "(10,) (128, 10)\n",
      "[  1.21662527e-01   1.26989279e-02   3.95593166e-01   7.55102038e-02\n",
      "   9.16107297e-02   6.70927949e-03   6.34269342e-02   9.09868162e-03\n",
      "   2.23383948e-01   3.05583002e-04]\n",
      "(10,) (128, 10)\n",
      "[  2.03739867e-01   5.63919283e-02   1.16024725e-03   5.05534606e-03\n",
      "   7.08651319e-02   2.38056816e-02   1.54320558e-03   3.73016903e-03\n",
      "   6.33530617e-01   1.77855880e-04]\n",
      "(10,) (128, 10)\n",
      "[  8.22716765e-03   1.07046144e-04   2.40601071e-06   3.58421734e-04\n",
      "   4.83874464e-03   5.52087903e-01   2.36655725e-03   1.35266368e-04\n",
      "   3.65023362e-03   4.28226262e-01]\n",
      "(10,) (128, 10)\n",
      "[  5.88941455e-01   2.36595541e-01   1.43856760e-02   5.70752716e-04\n",
      "   4.22533900e-02   4.62440221e-04   9.65402201e-02   3.30389687e-03\n",
      "   9.60397813e-03   7.34255929e-03]\n",
      "(10,) (128, 10)\n",
      "[  6.18945109e-04   6.29880071e-01   1.22973658e-02   7.66027160e-03\n",
      "   2.07383130e-02   3.01350257e-04   3.21044415e-01   2.66223750e-03\n",
      "   2.36617611e-03   2.43089697e-03]\n",
      "(10,) (128, 10)\n",
      "[  5.00719834e-05   6.16225239e-04   1.30677223e-03   6.09959543e-01\n",
      "   9.46828909e-03   1.22896003e-04   8.84363987e-03   3.47265811e-03\n",
      "   2.05453299e-02   3.45614552e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (128, 10)\n",
      "[  1.57272834e-02   1.39080745e-03   1.75766185e-01   7.18285799e-01\n",
      "   4.18737307e-02   1.40237631e-02   3.92265123e-04   1.67003620e-07\n",
      "   6.81148435e-04   3.18587944e-02]\n",
      "(10,) (128, 10)\n",
      "[  7.32446611e-02   1.51287233e-02   5.73944785e-02   1.28621543e-02\n",
      "   7.52406418e-01   1.68106966e-02   4.86561585e-05   4.26611910e-03\n",
      "   1.43741220e-02   5.34638502e-02]\n",
      "(10,) (128, 10)\n",
      "[  9.27551687e-02   6.63879141e-02   9.77356322e-05   6.03244524e-04\n",
      "   1.31302431e-01   6.31348372e-01   9.63639177e-05   7.96657614e-03\n",
      "   4.62842211e-02   2.31579915e-02]\n",
      "(10,) (128, 10)\n",
      "[  3.18487346e-01   6.60587626e-04   2.59117718e-04   2.05062106e-02\n",
      "   2.21954554e-01   1.07556678e-01   2.64477294e-05   9.94636491e-03\n",
      "   3.18839282e-01   1.76339911e-03]\n",
      "(10,) (128, 10)\n",
      "[  3.94538714e-04   7.36478157e-03   2.34678853e-04   1.40282046e-03\n",
      "   2.14999467e-01   7.02152491e-01   2.67725810e-03   3.30029125e-03\n",
      "   3.72483842e-02   3.02252918e-02]\n",
      "(10,) (128, 10)\n",
      "[  1.47490227e-03   1.44554833e-02   2.01800745e-03   2.91832443e-02\n",
      "   3.56960554e-05   6.48597702e-02   8.51725101e-01   5.37004125e-05\n",
      "   1.15733678e-02   2.46207211e-02]\n",
      "(10,) (128, 10)\n",
      "[  1.12852246e-01   3.08816247e-02   5.46211842e-03   1.38357619e-03\n",
      "   1.49694011e-01   2.42831334e-01   8.98368398e-06   1.26990546e-02\n",
      "   6.40879059e-03   4.37778264e-01]\n",
      "(10,) (128, 10)\n",
      "[  1.38412765e-03   6.18113787e-04   3.49210968e-05   9.90436137e-01\n",
      "   1.32443620e-06   2.22807736e-04   1.12383568e-03   4.08239011e-03\n",
      "   2.06235098e-03   3.40700171e-05]\n",
      "(10,) (128, 10)\n",
      "[  3.31718177e-02   4.36329690e-04   5.57090389e-03   6.02679001e-03\n",
      "   3.00349388e-03   5.39452049e-05   4.86853067e-03   7.81905510e-06\n",
      "   9.05936718e-01   4.09236737e-02]\n",
      "(10,) (128, 10)\n",
      "[ 0.00788294  0.00437139  0.00778901  0.08301481  0.00299249  0.00898889\n",
      "  0.00306701  0.27454257  0.00296787  0.60438305]\n",
      "(10,) (128, 10)\n",
      "[ 0.06451899  0.03648265  0.46041861  0.05159819  0.13994135  0.00914541\n",
      "  0.0006159   0.00096268  0.00153124  0.23478492]\n",
      "(10,) (128, 10)\n",
      "[  1.07391947e-03   1.02138467e-01   8.48289765e-03   2.83594839e-02\n",
      "   2.27399573e-01   1.46769537e-02   8.23981389e-02   1.33150695e-02\n",
      "   2.42617141e-04   5.21912932e-01]\n",
      "(10,) (128, 10)\n",
      "[  3.93478440e-05   3.54066287e-04   3.16265792e-01   3.18446875e-01\n",
      "   3.05257708e-01   4.10602055e-03   6.89500291e-03   3.90991132e-04\n",
      "   9.64319799e-04   4.72798347e-02]\n",
      "(10,) (128, 10)\n",
      "[ 0.00883012  0.00549704  0.34855109  0.08735912  0.36900187  0.03030502\n",
      "  0.00128458  0.00315736  0.12159614  0.02441768]\n",
      "(10,) (128, 10)\n",
      "[  2.52802297e-02   3.81154387e-04   2.11630300e-01   7.07606599e-03\n",
      "   6.05818331e-01   6.57032207e-02   2.07539066e-03   5.91199566e-03\n",
      "   2.09505614e-02   5.51726930e-02]\n",
      "(10,) (128, 10)\n",
      "[  1.69061914e-01   1.83356358e-04   6.64073101e-04   7.13996924e-05\n",
      "   2.19337526e-04   3.63052301e-02   4.97732937e-01   1.67947678e-06\n",
      "   3.96653451e-02   2.56094664e-01]\n",
      "(10,) (128, 10)\n",
      "[  1.03795493e-03   6.70082495e-02   4.57045913e-04   1.42829074e-02\n",
      "   1.66789010e-01   8.56339466e-03   7.51774432e-03   1.99949741e-03\n",
      "   7.23048270e-01   9.29590221e-03]\n",
      "(10,) (128, 10)\n",
      "[  3.05025518e-04   1.40584307e-02   6.64243996e-01   1.86722062e-03\n",
      "   1.96248293e-02   5.96929993e-03   2.14228127e-03   1.38546983e-02\n",
      "   2.11523578e-01   6.64107129e-02]\n",
      "(10,) (128, 10)\n",
      "[  1.05037242e-01   2.98830913e-03   2.86117836e-04   1.00615114e-01\n",
      "   2.71272234e-04   1.41257448e-02   1.80239603e-02   2.11863555e-02\n",
      "   7.30520248e-01   6.94560260e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.16455660e-03   1.97098343e-04   9.05522645e-01   3.69074784e-04\n",
      "   2.81547509e-05   8.07126090e-02   2.83135753e-03   3.06009781e-04\n",
      "   5.54266953e-05   8.81309435e-03]\n",
      "(10,) (128, 10)\n",
      "[  4.58415627e-01   4.95777056e-02   1.76481309e-03   3.72450203e-02\n",
      "   1.66732594e-01   1.28512997e-02   8.05075470e-05   2.60674775e-01\n",
      "   1.00038589e-04   1.25576295e-02]\n",
      "(10,) (128, 10)\n",
      "[  3.66544095e-03   5.00804484e-02   4.45352809e-04   1.32550747e-04\n",
      "   1.17346249e-03   2.60223242e-05   7.84024269e-06   7.30064154e-01\n",
      "   1.60900876e-01   5.35038374e-02]\n",
      "(10,) (128, 10)\n",
      "[  3.33016738e-03   1.07059590e-04   5.15426436e-05   7.64721725e-03\n",
      "   4.63059917e-02   1.59362477e-04   1.21702319e-02   9.29969013e-01\n",
      "   8.56215775e-06   2.50878802e-04]\n",
      "(10,) (128, 10)\n",
      "[  4.26533283e-04   3.22941504e-02   4.82221060e-02   4.42297220e-01\n",
      "   1.60207762e-03   8.12743511e-03   1.12547139e-02   2.13140592e-01\n",
      "   2.38583684e-01   4.05148091e-03]\n",
      "(10,) (128, 10)\n",
      "[  4.69649567e-05   1.92326009e-02   7.06342384e-02   9.09806322e-03\n",
      "   8.66380394e-01   2.43006107e-05   1.50525756e-03   2.67153904e-02\n",
      "   6.24968065e-03   1.13050111e-04]\n",
      "(10,) (128, 10)\n",
      "[ 0.2402439   0.52057469  0.04190543  0.01338147  0.00205614  0.03141089\n",
      "  0.00075545  0.04303768  0.10350257  0.00313188]\n",
      "(10,) (128, 10)\n",
      "[  1.82215835e-03   9.40780342e-03   6.27995357e-02   4.32912447e-02\n",
      "   1.87925587e-04   4.47846711e-01   1.45561680e-01   6.80425242e-02\n",
      "   2.63044727e-04   2.20777318e-01]\n",
      "(10,) (128, 10)\n",
      "[  1.24511188e-02   3.92004430e-01   2.84640621e-02   9.40356622e-05\n",
      "   6.33752934e-05   4.89361316e-01   1.04135573e-02   1.26206037e-02\n",
      "   1.34655340e-02   4.10619900e-02]\n",
      "(10,) (128, 10)\n",
      "[  1.02866045e-03   8.09952557e-01   9.20296407e-06   4.05032624e-04\n",
      "   5.79737498e-05   7.80778565e-03   6.81055826e-05   1.52528107e-01\n",
      "   2.80830823e-02   5.94405974e-05]\n",
      "(10,) (128, 10)\n",
      "[ 0.00672104  0.01383941  0.00377759  0.00560227  0.00301898  0.01734988\n",
      "  0.02790371  0.02185272  0.00759811  0.89233631]\n",
      "(10,) (128, 10)\n",
      "[  6.09072745e-01   4.62018438e-02   1.21338077e-01   1.57649722e-02\n",
      "   7.79291615e-02   1.36496080e-03   1.91573100e-03   5.32397971e-05\n",
      "   2.58794287e-04   1.26100510e-01]\n",
      "(10,) (128, 10)\n",
      "[  3.86036597e-02   9.03030813e-01   1.71258592e-03   2.30450672e-03\n",
      "   2.53423601e-02   1.30170110e-05   1.25721577e-04   2.83898674e-02\n",
      "   4.39517113e-04   3.79835874e-05]\n",
      "(10,) (128, 10)\n",
      "[  1.03957165e-04   5.54288737e-02   2.62582563e-02   2.30157096e-03\n",
      "   2.09508860e-03   2.76595098e-03   4.13069665e-01   3.54677177e-04\n",
      "   2.29439378e-01   2.68182576e-01]\n",
      "(10,) (128, 10)\n",
      "[  2.23057671e-03   4.00911667e-04   3.39608414e-05   3.17548393e-06\n",
      "   8.75055790e-02   2.29625292e-02   7.72875607e-01   9.43680704e-02\n",
      "   1.46249365e-02   4.99457773e-03]\n",
      "(10,) (128, 10)\n",
      "[  1.50232678e-02   2.55690128e-01   1.30351996e-02   1.16708390e-04\n",
      "   6.28616095e-01   2.55033461e-04   8.45523551e-03   1.63729899e-02\n",
      "   7.94872176e-03   5.44866808e-02]\n",
      "(10,) (128, 10)\n",
      "[  2.74010345e-05   4.85691167e-02   1.77004084e-04   3.97864002e-04\n",
      "   9.12977815e-01   2.57594784e-05   1.56957493e-03   2.34538387e-03\n",
      "   3.15659344e-02   2.34417291e-03]\n",
      "(10,) (128, 10)\n",
      "[  6.21199965e-01   1.18342659e-03   1.96060508e-01   8.79149411e-06\n",
      "   9.81166214e-03   4.63264883e-02   8.08345973e-02   3.62757617e-03\n",
      "   4.00154740e-02   9.31584393e-04]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-5628ea74d4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvolutionStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-463bb4a2361d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, iterations, print_step)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOPULATION_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mweights_try\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights_try\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_try\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-463bb4a2361d>\u001b[0m in \u001b[0;36m_get_weights_try\u001b[0;34m(self, w, p)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mjittered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGMA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mweights_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjittered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mweights_try\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EvolutionStrategy(model.get_weights(), get_reward, population_size=50, sigma=0.1, learning_rate=0.01)\n",
    "es.run(1000, print_step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1:1+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
